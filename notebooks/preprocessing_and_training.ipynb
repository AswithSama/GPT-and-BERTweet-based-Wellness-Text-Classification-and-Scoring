{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d1254527",
      "metadata": {
        "id": "d1254527"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dw_rNfEwZSYK",
      "metadata": {
        "id": "dw_rNfEwZSYK"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('updated_version2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "s4jxKpXTaGt7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4jxKpXTaGt7",
        "outputId": "18492d23-fa99-44a4-b53e-042322eb1bf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(54068, 19)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HYm9b58LRyFU",
      "metadata": {
        "id": "HYm9b58LRyFU"
      },
      "source": [
        "## Text preprocessing Pipeline Using SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "M3UuPiXKaHeB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "067fb3ab95b24becb73292ac7da21f15",
            "2932d165230042b7b1f7028e2f14d805",
            "c4d57a9a2eb545bc9af5263b3453bb4f",
            "8ce91c4875534a678c9dd2a2123e7394",
            "3cb1702023d44dceb0a387841fc7ade3",
            "cd709e77a89e455ba2d06dc19034fa4d",
            "79417e1e4b6643b7a50cd9b744eee536",
            "f760fd60a17f487291413fec137153dd",
            "a174a8c893f04c13af8ba0d6cb4ac51b",
            "87cf773da3d14953b888c69d9abde813",
            "97852c682044491aaafcfcddc228529b",
            "3b45d5d0c9564c4f86b6e980ac3e3119",
            "c3a62338819d4f8cba975375251514c6",
            "7325666d38d146379d4861e8a4f0628f",
            "ead5b8fbc4e348db9b06d0fd44a2005a",
            "c569e3e9409a4ba5a2b821a2b3ec6c1a",
            "f1283937b21a418c9931ed96e02b9315",
            "08a40e3ac5dd4b779d1202afe9ff3dd4",
            "7f7b893532c145cdae0572bd5c494efc",
            "d43f1725964d4d278bd6b2e3e3875dc3",
            "9d20ae96ac7e4d818cbd930ca1121dfe",
            "e636309ffb2643f3a940a867d87b596b",
            "b2160e500efc4d4086b44b83de64646a",
            "c69415d8379d4ee4af16467032c88f47",
            "2c8a5164a6cd4eed993dc0c5ea029077",
            "1905fa5bcd704293bcc05790f46e1132",
            "7728f9c1aaba4c058df6910def8ca905",
            "2f214bac406b4af598f1040a7c177c26",
            "ebc7a1e12c5a4dba8af5ad9495b8296a",
            "cdaedc56b51e45aa853d3e2da2cf1e0c",
            "5af646c2dee74eb083a467fd73047fb0",
            "399a396c695c4525a8bafabdc304a429",
            "9cfb59f0258642d38e4c51547d4e9c9b",
            "944dcae8e68d43379e95445aa545e3c7",
            "4541235900854d7cad8044efb78cebbe",
            "2df930357c924f19b21bd8db99cb7e16",
            "d96401da043a45d89c32fc4d403f895e",
            "4566db9c918040a683d9aa8c891dba7d",
            "ce1105bb04304f6e956a46a15f45eae0",
            "5ff2211a493545e19b21209c4e18f319",
            "89c55b64c2de4900b035d7bdbd57992f",
            "e90a0e3911d3445da616f5fb96bd6cd6",
            "8873c443c7dc47c18cb8859e64f23cc5",
            "851f2cb232aa43eb811beb297665d2c8"
          ]
        },
        "id": "M3UuPiXKaHeB",
        "outputId": "4168866d-f4ea-45f4-c87e-9b4382e3be86"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from transformers import AutoTokenizer\n",
        "import re\n",
        "import emoji\n",
        "\n",
        "# Load spaCy (no parser/ner for speed)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"textcat\"])\n",
        "\n",
        "# Load BERTweet tokenizer\n",
        "bertweet_tok = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
        "\n",
        "# Keep negations\n",
        "negations = {\"no\", \"not\", \"nor\", \"n't\"}\n",
        "context_words = {\n",
        "    # First-person\n",
        "    \"i\", \"me\", \"my\", \"mine\", \"myself\", \"we\", \"us\", \"our\", \"ours\", \"ourselves\",\n",
        "\n",
        "    # Second-person\n",
        "    \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
        "\n",
        "    # Third-person singular\n",
        "    \"he\", \"him\", \"his\", \"himself\",\n",
        "    \"she\", \"her\", \"hers\", \"herself\",\n",
        "    \"it\", \"its\", \"itself\",\n",
        "\n",
        "    # Third-person plural\n",
        "    \"they\", \"them\", \"their\", \"theirs\", \"themselves\",\n",
        "\n",
        "    # Demonstratives\n",
        "    \"this\", \"that\", \"these\", \"those\",\n",
        "\n",
        "    # Interrogatives / relatives\n",
        "    \"who\", \"whom\", \"whose\", \"which\", \"what\",\n",
        "\n",
        "    # Possessive determiners often pruned but useful in context\n",
        "    \"own\",\n",
        "\n",
        "    # Common discourse/contextual markers\n",
        "    \"here\", \"there\", \"where\", \"when\", \"why\", \"how\"\n",
        "}\n",
        "\n",
        "stop_words = STOP_WORDS - negations-context_words\n",
        "\n",
        "# Emoji regex (keeps most Unicode emojis)\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map\n",
        "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "    u\"\\U00002700-\\U000027BF\"  # dingbats\n",
        "    u\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols\n",
        "    u\"\\U00002600-\\U000026FF\"  # misc symbols\n",
        "    \"]+\", flags=re.UNICODE)\n",
        "\n",
        "def emoji_to_text(e: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert emoji to its text alias using emoji.demojize\n",
        "    e.g., ðŸ˜‚ -> \":face_with_tears_of_joy:\"\n",
        "    \"\"\"\n",
        "    return emoji.demojize(e)\n",
        "def is_emoji(token: str) -> bool:\n",
        "    return bool(emoji_pattern.fullmatch(token))\n",
        "\n",
        "def normalize_punct(tok: str) -> str | None:\n",
        "    \"\"\"Normalize emotional punctuation runs.\"\"\"\n",
        "    if set(tok) == {\"!\"}:\n",
        "        return \"!\"\n",
        "    if set(tok) == {\"?\"}:\n",
        "        return \"?\"\n",
        "    if set(tok) == {\".\"} and len(tok) >= 3:\n",
        "        return \"...\"\n",
        "    return None\n",
        "\n",
        "def in_bertweet(token: str) -> bool:\n",
        "    \"\"\"Check if token is in BERTweet vocab (not [UNK]).\"\"\"\n",
        "    return bertweet_tok.convert_tokens_to_ids(token) != bertweet_tok.unk_token_id\n",
        "\n",
        "def preprocessing(doc):\n",
        "    tokens = []\n",
        "\n",
        "    last_punct = None      # collapse !!!!! or ??? or ...\n",
        "    last_emoji = None      # collapse repeated emojis\n",
        "\n",
        "    for tok in doc:\n",
        "        t = tok.text\n",
        "        lower = t.lower()\n",
        "\n",
        "        # ---------------------------\n",
        "        # EMOJIS (keep one per run)\n",
        "        # ---------------------------\n",
        "        if is_emoji(t):\n",
        "            alias = emoji_to_text(t)   # ðŸ˜‚ -> face_with_tears_of_joy\n",
        "            if alias != last_emoji and in_bertweet(alias):\n",
        "                tokens.append(alias)\n",
        "                last_emoji = alias\n",
        "            last_punct = None\n",
        "            continue\n",
        "\n",
        "        # ---------------------------\n",
        "        # PUNCTUATION (keep ! ? ...)\n",
        "        # ---------------------------\n",
        "        if tok.is_punct:\n",
        "            if t in {\"!\", \"?\", \"...\"}:\n",
        "                if t != last_punct:\n",
        "                    tokens.append(t)\n",
        "                    last_punct = t\n",
        "            else:\n",
        "                last_punct = None\n",
        "            last_emoji = None\n",
        "            continue\n",
        "\n",
        "        # ---------------------------\n",
        "        # NEGATION handling\n",
        "        # didn't -> not\n",
        "        # ---------------------------\n",
        "        if lower in {\"n't\", \"'nt\"}:\n",
        "            tokens.append(\"not\")\n",
        "            last_punct = None\n",
        "            last_emoji = None\n",
        "            continue\n",
        "\n",
        "        # ---------------------------\n",
        "        # NUMBERS (keep)\n",
        "        # useful for health/metrics\n",
        "        # ---------------------------\n",
        "        if tok.like_num:\n",
        "            tokens.append(lower)\n",
        "            last_punct = None\n",
        "            last_emoji = None\n",
        "            continue\n",
        "\n",
        "        # ---------------------------\n",
        "        # WORDS\n",
        "        # ---------------------------\n",
        "        if tok.is_alpha:\n",
        "            lemma = tok.lemma_.lower()\n",
        "\n",
        "            # fix spaCy pronoun bug\n",
        "            if lemma == \"-pron-\":\n",
        "                lemma = lower\n",
        "\n",
        "            if lemma not in stop_words and in_bertweet(lemma):\n",
        "                tokens.append(lemma)\n",
        "\n",
        "            last_punct = None\n",
        "            last_emoji = None\n",
        "            continue\n",
        "\n",
        "        # reset runs for anything else\n",
        "        last_punct = None\n",
        "        last_emoji = None\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "# --- Apply to DataFrame ---\n",
        "text_col = \"cleaned_text\"\n",
        "wellness_cols = df.drop(columns=['text']).columns\n",
        "\n",
        "corpus = []\n",
        "for doc in nlp.pipe(df['text'].astype(str), batch_size=512):\n",
        "    tokens = preprocessing(doc)\n",
        "    corpus.append(\" \".join(tokens))\n",
        "\n",
        "processed_df = pd.DataFrame({\"cleaned_text\": corpus}, index=df.index)\n",
        "processed_df = pd.concat([processed_df, df[wellness_cols]], axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08060c57",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['text'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 111\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# --- Apply to DataFrame ---\u001b[39;00m\n\u001b[32m    110\u001b[39m text_col = \u001b[33m\"\u001b[39m\u001b[33mcleaned_text\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m emotion_cols = \u001b[43mprocessed_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.columns\n\u001b[32m    113\u001b[39m corpus = []\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m nlp.pipe(processed_df[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m), batch_size=\u001b[32m512\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/site-packages/pandas/core/frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/site-packages/pandas/core/generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/site-packages/pandas/core/generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
            "\u001b[31mKeyError\u001b[39m: \"['text'] not found in axis\""
          ]
        }
      ],
      "source": [
        "'''\n",
        "import re\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from transformers import AutoTokenizer\n",
        "import emoji\n",
        "\n",
        "# Load spaCy (no parser/ner for speed)\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"textcat\"])\n",
        "\n",
        "# Load BERTweet tokenizer\n",
        "bertweet_tok = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
        "\n",
        "# Emoji regex (keeps most Unicode emojis)\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map\n",
        "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "    u\"\\U00002700-\\U000027BF\"  # dingbats\n",
        "    u\"\\U0001F900-\\U0001F9FF\"  # supplemental symbols\n",
        "    u\"\\U00002600-\\U000026FF\"  # misc symbols\n",
        "    \"]+\", flags=re.UNICODE)\n",
        "\n",
        "def emoji_to_text(e: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert emoji to its text alias using emoji.demojize\n",
        "    e.g., ðŸ˜‚ -> \":face_with_tears_of_joy:\"\n",
        "    \"\"\"\n",
        "    return emoji.demojize(e)\n",
        "def is_emoji(token: str) -> bool:\n",
        "    return bool(emoji_pattern.fullmatch(token))\n",
        "\n",
        "def normalize_punct(tok: str) -> str | None:\n",
        "    \"\"\"Normalize emotional punctuation runs.\"\"\"\n",
        "    if set(tok) == {\"!\"}:\n",
        "        return \"!\"\n",
        "    if set(tok) == {\"?\"}:\n",
        "        return \"?\"\n",
        "    if set(tok) == {\".\"} and len(tok) >= 3:\n",
        "        return \"...\"\n",
        "    return None\n",
        "\n",
        "def in_bertweet(token: str) -> bool:\n",
        "    \"\"\"Check if token is in BERTweet vocab (not [UNK]).\"\"\"\n",
        "    return bertweet_tok.convert_tokens_to_ids(token) != bertweet_tok.unk_token_id\n",
        "\n",
        "def preprocessing(doc):\n",
        "    tokens = []\n",
        "    last_punct = None    # track last emitted '!' or '?'\n",
        "    last_emoji = None    # track last emitted emoji alias\n",
        "\n",
        "    for tok in doc:\n",
        "        t = tok.text\n",
        "\n",
        "        # --- EMOJIS (one emoji per token; collapse consecutive repeats) ---\n",
        "        if is_emoji(t):\n",
        "            alias = emoji_to_text(t)              # e.g. ðŸ˜‚ -> 'face_with_tears_of_joy'\n",
        "            if in_bertweet(alias) and alias != last_emoji:\n",
        "                tokens.append(alias)\n",
        "                last_emoji = alias\n",
        "            # break punctuation run regardless\n",
        "            last_punct = None\n",
        "            continue\n",
        "\n",
        "        # --- PUNCT (keep only ! and ?; collapse consecutive repeats) ---\n",
        "        if tok.is_punct:\n",
        "            if t in {\"!\", \"?\",\"...\"}:\n",
        "                if t != last_punct:\n",
        "                    tokens.append(t)             # keep the first in a run\n",
        "                    last_punct = t\n",
        "            else:\n",
        "                # ignore other punctuation; also break the run\n",
        "                last_punct = None\n",
        "            # break emoji run\n",
        "            last_emoji = None\n",
        "            continue\n",
        "\n",
        "        # --- CONTRACTION NEGATION (spaCy splits \"didn't\" -> \"did\" + \"n't\") ---\n",
        "        if t.lower() in {\"n't\", \"'nt\"}:\n",
        "            tokens.append(\"not\")\n",
        "            last_punct = None\n",
        "            last_emoji = None\n",
        "            continue\n",
        "\n",
        "        # --- WORDS ---\n",
        "        if tok.is_alpha:\n",
        "            lemma = tok.lemma_.lower()\n",
        "            if lemma == \"-pron-\":\n",
        "                lemma = t.lower()\n",
        "            if lemma not in stop_words and in_bertweet(lemma):\n",
        "                tokens.append(lemma)\n",
        "            last_punct = None\n",
        "            last_emoji = None\n",
        "            continue\n",
        "\n",
        "        # anything else breaks runs\n",
        "        last_punct = None\n",
        "        last_emoji = None\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "\n",
        "# --- Apply to DataFrame ---\n",
        "text_col = \"cleaned_text\"\n",
        "emotion_cols = processed_df.drop(columns=['text']).columns\n",
        "\n",
        "corpus = []\n",
        "for doc in nlp.pipe(processed_df['text'].astype(str), batch_size=512):\n",
        "    tokens = preprocessing(doc)\n",
        "    corpus.append(\" \".join(tokens))\n",
        "\n",
        "processed_df = pd.DataFrame({\"cleaned_text\": corpus}, index=processed_df.index)\n",
        "processed_df = pd.concat([processed_df, processed_df[emotion_cols]], axis=1)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "YoBQ2qwRdQgs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "YoBQ2qwRdQgs",
        "outputId": "7fcb600a-ff86-4648-b50d-989675b6e1a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>physical_wellness</th>\n",
              "      <th>not_physical_wellness</th>\n",
              "      <th>intellectual_wellness</th>\n",
              "      <th>occupational_wellness</th>\n",
              "      <th>not_occupational_wellness</th>\n",
              "      <th>financial_wellness</th>\n",
              "      <th>not_financial_wellness</th>\n",
              "      <th>social_interaction_wellness</th>\n",
              "      <th>not_social_interaction_wellness</th>\n",
              "      <th>spiritual_wellness</th>\n",
              "      <th>mental_wellness</th>\n",
              "      <th>not_mental_wellness</th>\n",
              "      <th>compassion_contribution_wellness</th>\n",
              "      <th>family_and_caregiving</th>\n",
              "      <th>not_family_and_caregiving</th>\n",
              "      <th>leisure_and_travel</th>\n",
              "      <th>life_events_transitions</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>teacher i stumble home exhausted numb like day...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>my manager tiny task i nurse it i feel like ro...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>project software engineer feel like rerun ther...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i this cashier job paycheck little work not me...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>culture my warehouse team toxic comment gossip...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        cleaned_text  physical_wellness  \\\n",
              "0  teacher i stumble home exhausted numb like day...                  0   \n",
              "1  my manager tiny task i nurse it i feel like ro...                  0   \n",
              "2  project software engineer feel like rerun ther...                  0   \n",
              "3  i this cashier job paycheck little work not me...                  0   \n",
              "4  culture my warehouse team toxic comment gossip...                  0   \n",
              "\n",
              "   not_physical_wellness  intellectual_wellness  occupational_wellness  \\\n",
              "0                      1                      0                      0   \n",
              "1                      0                      0                      0   \n",
              "2                      0                      0                      0   \n",
              "3                      0                      0                      0   \n",
              "4                      0                      0                      0   \n",
              "\n",
              "   not_occupational_wellness  financial_wellness  not_financial_wellness  \\\n",
              "0                          1                   0                       0   \n",
              "1                          1                   0                       0   \n",
              "2                          1                   0                       0   \n",
              "3                          1                   1                       0   \n",
              "4                          1                   0                       0   \n",
              "\n",
              "   social_interaction_wellness  not_social_interaction_wellness  \\\n",
              "0                            0                                0   \n",
              "1                            0                                0   \n",
              "2                            0                                0   \n",
              "3                            0                                0   \n",
              "4                            0                                1   \n",
              "\n",
              "   spiritual_wellness  mental_wellness  not_mental_wellness  \\\n",
              "0                   0                0                    0   \n",
              "1                   0                0                    0   \n",
              "2                   0                0                    0   \n",
              "3                   0                0                    0   \n",
              "4                   0                0                    0   \n",
              "\n",
              "   compassion_contribution_wellness  family_and_caregiving  \\\n",
              "0                                 0                      0   \n",
              "1                                 0                      0   \n",
              "2                                 0                      0   \n",
              "3                                 0                      0   \n",
              "4                                 0                      0   \n",
              "\n",
              "   not_family_and_caregiving  leisure_and_travel  life_events_transitions  \\\n",
              "0                          0                   0                        0   \n",
              "1                          0                   0                        0   \n",
              "2                          0                   0                        0   \n",
              "3                          0                   0                        0   \n",
              "4                          0                   0                        0   \n",
              "\n",
              "   neutral  \n",
              "0        0  \n",
              "1        0  \n",
              "2        0  \n",
              "3        0  \n",
              "4        0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "Kkpt3K18Shr6",
      "metadata": {
        "id": "Kkpt3K18Shr6"
      },
      "outputs": [],
      "source": [
        "if 'Unnamed: 0' in processed_df.columns:\n",
        "    processed_df.drop('Unnamed: 0', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "O8TXqewsS5Jd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8TXqewsS5Jd",
        "outputId": "aaa46bed-798a-48df-e6bc-a4f49ae26280"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['cleaned_text', 'physical_wellness', 'not_physical_wellness',\n",
              "       'intellectual_wellness', 'occupational_wellness',\n",
              "       'not_occupational_wellness', 'financial_wellness',\n",
              "       'not_financial_wellness', 'social_interaction_wellness',\n",
              "       'not_social_interaction_wellness', 'spiritual_wellness',\n",
              "       'mental_wellness', 'not_mental_wellness',\n",
              "       'compassion_contribution_wellness', 'family_and_caregiving',\n",
              "       'not_family_and_caregiving', 'leisure_and_travel',\n",
              "       'life_events_transitions', 'neutral'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "NaFUzUByfaby",
      "metadata": {
        "id": "NaFUzUByfaby"
      },
      "outputs": [],
      "source": [
        "y=processed_df.drop('cleaned_text',axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8427kj2Tx_qG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "8427kj2Tx_qG",
        "outputId": "66ef5f81-0025-48f0-dd43-832e3adb3225"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>physical_wellness</th>\n",
              "      <th>not_physical_wellness</th>\n",
              "      <th>intellectual_wellness</th>\n",
              "      <th>occupational_wellness</th>\n",
              "      <th>not_occupational_wellness</th>\n",
              "      <th>financial_wellness</th>\n",
              "      <th>not_financial_wellness</th>\n",
              "      <th>social_interaction_wellness</th>\n",
              "      <th>not_social_interaction_wellness</th>\n",
              "      <th>spiritual_wellness</th>\n",
              "      <th>mental_wellness</th>\n",
              "      <th>not_mental_wellness</th>\n",
              "      <th>compassion_contribution_wellness</th>\n",
              "      <th>family_and_caregiving</th>\n",
              "      <th>not_family_and_caregiving</th>\n",
              "      <th>leisure_and_travel</th>\n",
              "      <th>life_events_transitions</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   physical_wellness  not_physical_wellness  intellectual_wellness  \\\n",
              "0                  0                      1                      0   \n",
              "1                  0                      0                      0   \n",
              "2                  0                      0                      0   \n",
              "3                  0                      0                      0   \n",
              "4                  0                      0                      0   \n",
              "\n",
              "   occupational_wellness  not_occupational_wellness  financial_wellness  \\\n",
              "0                      0                          1                   0   \n",
              "1                      0                          1                   0   \n",
              "2                      0                          1                   0   \n",
              "3                      0                          1                   1   \n",
              "4                      0                          1                   0   \n",
              "\n",
              "   not_financial_wellness  social_interaction_wellness  \\\n",
              "0                       0                            0   \n",
              "1                       0                            0   \n",
              "2                       0                            0   \n",
              "3                       0                            0   \n",
              "4                       0                            0   \n",
              "\n",
              "   not_social_interaction_wellness  spiritual_wellness  mental_wellness  \\\n",
              "0                                0                   0                0   \n",
              "1                                0                   0                0   \n",
              "2                                0                   0                0   \n",
              "3                                0                   0                0   \n",
              "4                                1                   0                0   \n",
              "\n",
              "   not_mental_wellness  compassion_contribution_wellness  \\\n",
              "0                    0                                 0   \n",
              "1                    0                                 0   \n",
              "2                    0                                 0   \n",
              "3                    0                                 0   \n",
              "4                    0                                 0   \n",
              "\n",
              "   family_and_caregiving  not_family_and_caregiving  leisure_and_travel  \\\n",
              "0                      0                          0                   0   \n",
              "1                      0                          0                   0   \n",
              "2                      0                          0                   0   \n",
              "3                      0                          0                   0   \n",
              "4                      0                          0                   0   \n",
              "\n",
              "   life_events_transitions  neutral  \n",
              "0                        0        0  \n",
              "1                        0        0  \n",
              "2                        0        0  \n",
              "3                        0        0  \n",
              "4                        0        0  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "WDb-rm3hgLaX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "47b8a480b521436baf978ae4a8db6d96",
            "71c498b979e64a118aeb6fee90a16ffc",
            "ffa01401661c44b38e164b4787170663",
            "d31c0b7e91354b22a334d8333dec2a31",
            "2dd846a313e245fab09259d31a0475b5",
            "5ec8dfb2d1424a0f99836baa3670a112",
            "3442c7e3b3fa45d58e9636e9036aee7f",
            "03ff24d8b1214364851744243890cdee",
            "3f1bb095fdd04ef3843b601b4e3e9d73",
            "878573711bd34010b2ad8c9572ab8f13",
            "40943c2d228f4b38a067cc0e16919f3a"
          ]
        },
        "id": "WDb-rm3hgLaX",
        "outputId": "f509996b-37c6-4bb5-8215-d666a3d583d0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch, re\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "MODEL_NAME = \"vinai/bertweet-base\"   # 768-d; use \"vinai/bertweet-large\" for 1024-d\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "label_cols = processed_df.drop('cleaned_text', axis=1).columns.tolist()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "USER_RE = re.compile(r\"@\\w+\")\n",
        "URL_RE  = re.compile(r\"http\\S+|www\\.\\S+\")\n",
        "def normalize_tweet(t: str) -> str:\n",
        "    t = USER_RE.sub(\"<user>\", t)\n",
        "    t = URL_RE.sub(\"<url>\", t)\n",
        "    return t"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rOlQTniFaeZa",
      "metadata": {
        "id": "rOlQTniFaeZa"
      },
      "source": [
        "## Model Building and Making it ready for training\n",
        "1. Selective layer freezing/unfreezing (top 3 unfrozen)\n",
        "2. Strided tokenization for long sequences (>128)\n",
        "\n",
        "3. Custom Dataset and batch collate\n",
        "\n",
        "4. Dynamic padding and truncation\n",
        "\n",
        "5. Class balancing with pos_weight\n",
        "\n",
        "6. Mean-pooling sentence representation\n",
        "\n",
        "7. Lightweight dropout + linear classification head\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2OuZwx9VqpX5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "2OuZwx9VqpX5",
        "outputId": "90ef6071-1f99-4162-de1f-d9ba557bcf1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting peft\n",
            "  Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from peft) (25.0)\n",
            "Requirement already satisfied: psutil in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from peft) (5.9.0)\n",
            "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from peft) (2.8.0)\n",
            "Requirement already satisfied: transformers in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from peft) (4.55.2)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from peft) (4.67.1)\n",
            "Collecting accelerate>=0.21.0 (from peft)\n",
            "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: safetensors in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from peft) (0.6.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from peft) (0.34.4)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2025.7.0)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (1.1.7)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from torch>=1.13.0->peft) (78.1.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.8.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from transformers->peft) (2025.7.34)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/py312fix/lib/python3.12/site-packages (from transformers->peft) (0.21.4)\n",
            "Downloading peft-0.18.1-py3-none-any.whl (556 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m557.0/557.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
            "Installing collected packages: accelerate, peft\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [peft][32m1/2\u001b[0m [peft]\n",
            "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 peft-0.18.1\n"
          ]
        }
      ],
      "source": [
        "!pip install peft\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5kyCxPyrnC0R",
      "metadata": {
        "id": "5kyCxPyrnC0R"
      },
      "source": [
        "## Working Training part using 3 unfreezed layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "DkawoahXktwr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkawoahXktwr",
        "outputId": "af10ecb4-93ec-41ec-b3f7-e6ce518aa6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder.layer.0\n"
          ]
        }
      ],
      "source": [
        "# Dataset: return raw text + labels only (no tokenization here)\n",
        "from torch.utils.data import random_split\n",
        "import re, copy, math, torch, torch.nn as nn, torch.optim as optim\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import re\n",
        "class LabeledTweetDataset(Dataset):\n",
        "    def __init__(self, df, text_col: str, label_cols, max_len: int = 128):\n",
        "        self.texts  = df[text_col].astype(str).tolist()\n",
        "        self.labels = df[label_cols].astype(\"float32\").values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return {\n",
        "            \"text\": normalize_tweet(self.texts[i]),\n",
        "            \"labels\": torch.from_numpy(self.labels[i])\n",
        "        }\n",
        "\n",
        "# Collate: tokenize the whole batch at once (fast) and pad\n",
        "def build_collate(tokenizer, max_len=128, stride=None):\n",
        "    def collate(batch):\n",
        "        texts  = [b[\"text\"] for b in batch]\n",
        "        labels = torch.stack([b[\"labels\"] for b in batch], dim=0)\n",
        "\n",
        "        kwargs = dict(\n",
        "            truncation=True,\n",
        "            max_length=max_len,\n",
        "            padding=True,           # dynamic padding to longest in this batch\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        if stride is not None:\n",
        "            kwargs.update(\n",
        "                stride=stride,\n",
        "                return_overflowing_tokens=True\n",
        "            )\n",
        "        enc = tokenizer(texts, padding=True,truncation=True,max_length=128,return_tensors=\"pt\")\n",
        "\n",
        "        # If using stride, duplicate labels per overflow chunk\n",
        "        if \"overflow_to_sample_mapping\" in enc:\n",
        "            mapping = enc[\"overflow_to_sample_mapping\"]\n",
        "            labels = labels[mapping]\n",
        "\n",
        "        enc[\"labels\"] = labels\n",
        "        return enc\n",
        "    return collate\n",
        "max_len   = 128\n",
        "batch_sz  = 16\n",
        "dataset   = LabeledTweetDataset(processed_df, text_col=text_col, label_cols=label_cols, max_len=max_len)\n",
        "\n",
        "val_frac  = 0.2\n",
        "val_size  = int(len(dataset) * val_frac)\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "collate_fn = build_collate(tokenizer, max_len=128, stride=32)  # or stride=None\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True,collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=16, shuffle=False, num_workers=4,collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# ==== 0) Imports ====\n",
        "##------------------------TRAINING STARTS HERE##-------------------\n",
        "\n",
        "\n",
        "# ==== 1) Class weights (your code, with dtype/device)\n",
        "with torch.no_grad():\n",
        "    Y_np = processed_df[label_cols].astype(\"float32\").values\n",
        "Y_t = torch.tensor(Y_np, dtype=torch.float32)\n",
        "N   = Y_t.shape[0]\n",
        "pos_counts = Y_t.sum(dim=0)\n",
        "neg_counts = N - pos_counts\n",
        "pos_weight = (neg_counts / (pos_counts + 1e-8)).to(DEVICE).float()\n",
        "\n",
        "class BertweetClassifier(nn.Module):\n",
        "    def __init__(self, model_name=\"vinai/bertweet-base\", num_labels=18,\n",
        "                 lora_r=8, lora_alpha=16, lora_dropout=0.05):\n",
        "        super().__init__()\n",
        "        # Base encoder\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)  # Roberta-like (BERTweet)\n",
        "\n",
        "        for n, _ in self.encoder.named_modules():\n",
        "          if \"layer.0\" in n:   # show where the first layer lives\n",
        "              print(n)\n",
        "              break\n",
        "\n",
        "\n",
        "        # Freeze base weights in ALL layers first; PEFT adapters remain trainable\n",
        "        for n, p in self.encoder.named_parameters():\n",
        "                p.requires_grad = False\n",
        "        total_layers = self.encoder.config.num_hidden_layers\n",
        "        for idx in range(total_layers - 3, total_layers):   # 9,10,11 for 12-layer base\n",
        "            for p in self.encoder.encoder.layer[idx].parameters():\n",
        "                p.requires_grad = True\n",
        "\n",
        "        # Classification head\n",
        "        hidden_size = self.encoder.config.hidden_size  # 768 for bertweet-base\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # mean-pool over valid tokens\n",
        "        mask = attention_mask.unsqueeze(-1)\n",
        "        x = (out.last_hidden_state * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n",
        "        x = self.dropout(x)\n",
        "        return self.classifier(x)  # logits [B, num_labels]\n",
        "\n",
        "model = BertweetClassifier(num_labels=len(label_cols)).to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cjcyDRCFmdHE",
      "metadata": {
        "id": "cjcyDRCFmdHE"
      },
      "source": [
        "## testing with peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "T0DF9GTfmfYo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "T0DF9GTfmfYo",
        "outputId": "2386c0eb-2633-435c-9606-7a86f438561d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'import torch\\nimport torch.nn as nn\\nfrom transformers import AutoModel\\nfrom peft import LoraConfig, get_peft_model, TaskType\\n# Dataset: return raw text + labels only (no tokenization here)\\nfrom torch.utils.data import random_split\\nfrom transformers import AutoModel, AutoTokenizer\\n\\nclass LabeledTweetDataset(Dataset):\\n    def __init__(self, df, text_col: str, label_cols, max_len: int = 128):\\n        self.texts  = df[text_col].astype(str).tolist()\\n        self.labels = df[label_cols].astype(\"float32\").values\\n        self.max_len = max_len\\n\\n    def __len__(self):\\n        return len(self.texts)\\n\\n    def __getitem__(self, i):\\n        return {\\n            \"text\": normalize_tweet(self.texts[i]),\\n            \"labels\": torch.from_numpy(self.labels[i])\\n        }\\n\\n# Collate: tokenize the whole batch at once (fast) and pad\\ndef build_collate(tokenizer, max_len=128, stride=None):\\n    def collate(batch):\\n        texts  = [b[\"text\"] for b in batch]\\n        labels = torch.stack([b[\"labels\"] for b in batch], dim=0)\\n\\n        kwargs = dict(\\n            truncation=True,\\n            max_length=max_len,\\n            padding=True,           # dynamic padding to longest in this batch\\n            return_attention_mask=True,\\n            return_tensors=\"pt\"\\n        )\\n        if stride is not None:\\n            kwargs.update(\\n                stride=stride,\\n                return_overflowing_tokens=True\\n            )\\n        enc = tokenizer(texts, padding=True,truncation=True,max_length=128,return_tensors=\"pt\")\\n\\n        # If using stride, duplicate labels per overflow chunk\\n        if \"overflow_to_sample_mapping\" in enc:\\n            mapping = enc[\"overflow_to_sample_mapping\"]\\n            labels = labels[mapping]\\n\\n        enc[\"labels\"] = labels\\n        return enc\\n    return collate\\nmax_len   = 128\\nbatch_sz  = 16\\ndataset   = LabeledTweetDataset(processed_df, text_col=text_col, label_cols=label_cols, max_len=max_len)\\n\\nval_frac  = 0.2\\nval_size  = int(len(dataset) * val_frac)\\ntrain_size = len(dataset) - val_size\\n\\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\\n\\n\\ncollate_fn = build_collate(tokenizer, max_len=128, stride=32)  # or stride=None\\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True,collate_fn=collate_fn)\\nval_loader   = DataLoader(val_ds,   batch_size=16, shuffle=False,collate_fn=collate_fn)\\n\\n\\n# ==== 0) Imports ====\\n##------------------------TRAINING STARTS HERE##-------------------\\n\\n# ==== 1) Class weights (your code, with dtype/device)\\nwith torch.no_grad():\\n    Y_np = processed_df[label_cols].astype(\"float32\").values\\nY_t = torch.tensor(Y_np, dtype=torch.float32)\\nN   = Y_t.shape[0]\\npos_counts = Y_t.sum(dim=0)\\nneg_counts = N - pos_counts\\npos_weight = (neg_counts / (pos_counts + 1e-8)).to(DEVICE).float()\\n\\nclass BertweetClassifier(nn.Module):\\n    def __init__(self, model_name=\"vinai/bertweet-base\", num_labels=18,\\n                 lora_r=8, lora_alpha=16, lora_dropout=0.05):\\n        super().__init__()\\n\\n        # 1) Load the base encoder\\n        base_encoder = AutoModel.from_pretrained(model_name)  # BERTweet = RoBERTa architecture\\n\\n        # 2) Freeze ALL base weights\\n        for p in base_encoder.parameters():\\n            p.requires_grad = False\\n\\n        # 3) Attach LoRA adapters (these will be the ONLY trainable params inside the encoder)\\n        # For RoBERTa/BERTweet, typical attention linear layers are named: query, key, value, and output.dense\\n        # You can safely target: [\"query\", \"key\", \"value\", \"dense\"] (matches attention projections + output)\\n        lora_cfg = LoraConfig(\\n            r=lora_r,\\n            lora_alpha=lora_alpha,\\n            lora_dropout=lora_dropout,\\n            bias=\"none\",\\n            task_type=TaskType.SEQ_CLS,\\n        )\\n             config = LoraConfig(\\n          r=16, #attention heads\\n          lora_alpha=32, #alpha scaling\\n          # target_modules=[\"q_proj\", \"v_proj\"], #if you know the\\n          lora_dropout=0.05,\\n          bias=\"none\",\\n          task_type=\"CAUSAL_LM\" # set this for CLM or Seq2Seq\\n          )\\n        self.encoder = get_peft_model(base_encoder, lora_cfg)\\n\\n        # 4) Classification head (kept trainable)\\n        hidden_size = self.encoder.config.hidden_size  # 768 for bertweet-base\\n        self.dropout = nn.Dropout(0.1)\\n        self.classifier = nn.Linear(hidden_size, num_labels)\\n\\n        # (optional) sanity check: print trainable parameter count\\n        trainable, total = 0, 0\\n        for n, p in self.named_parameters():\\n            total += p.numel()\\n            if p.requires_grad:\\n                trainable += p.numel()\\n        print(f\"Trainable params: {trainable:,} / {total:,}\")\\n\\n\\n    def forward(self, input_ids, attention_mask):\\n        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\\n        # mean-pool over valid tokens\\n        mask = attention_mask.unsqueeze(-1)\\n        x = (out.last_hidden_state * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\\n        x = self.dropout(x)\\n        return self.classifier(x)  # logits [B, num_labels]\\n\\n\\nmodel = BertweetClassifier(num_labels=len(label_cols)).to(DEVICE)\\n'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "# Dataset: return raw text + labels only (no tokenization here)\n",
        "from torch.utils.data import random_split\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "class LabeledTweetDataset(Dataset):\n",
        "    def __init__(self, df, text_col: str, label_cols, max_len: int = 128):\n",
        "        self.texts  = df[text_col].astype(str).tolist()\n",
        "        self.labels = df[label_cols].astype(\"float32\").values\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return {\n",
        "            \"text\": normalize_tweet(self.texts[i]),\n",
        "            \"labels\": torch.from_numpy(self.labels[i])\n",
        "        }\n",
        "\n",
        "# Collate: tokenize the whole batch at once (fast) and pad\n",
        "def build_collate(tokenizer, max_len=128, stride=None):\n",
        "    def collate(batch):\n",
        "        texts  = [b[\"text\"] for b in batch]\n",
        "        labels = torch.stack([b[\"labels\"] for b in batch], dim=0)\n",
        "\n",
        "        kwargs = dict(\n",
        "            truncation=True,\n",
        "            max_length=max_len,\n",
        "            padding=True,           # dynamic padding to longest in this batch\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        if stride is not None:\n",
        "            kwargs.update(\n",
        "                stride=stride,\n",
        "                return_overflowing_tokens=True\n",
        "            )\n",
        "        enc = tokenizer(texts, padding=True,truncation=True,max_length=128,return_tensors=\"pt\")\n",
        "\n",
        "        # If using stride, duplicate labels per overflow chunk\n",
        "        if \"overflow_to_sample_mapping\" in enc:\n",
        "            mapping = enc[\"overflow_to_sample_mapping\"]\n",
        "            labels = labels[mapping]\n",
        "\n",
        "        enc[\"labels\"] = labels\n",
        "        return enc\n",
        "    return collate\n",
        "max_len   = 128\n",
        "batch_sz  = 16\n",
        "dataset   = LabeledTweetDataset(processed_df, text_col=text_col, label_cols=label_cols, max_len=max_len)\n",
        "\n",
        "val_frac  = 0.2\n",
        "val_size  = int(len(dataset) * val_frac)\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "collate_fn = build_collate(tokenizer, max_len=128, stride=32)  # or stride=None\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True,collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=16, shuffle=False,collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "# ==== 0) Imports ====\n",
        "##------------------------TRAINING STARTS HERE##-------------------\n",
        "\n",
        "# ==== 1) Class weights (your code, with dtype/device)\n",
        "with torch.no_grad():\n",
        "    Y_np = processed_df[label_cols].astype(\"float32\").values\n",
        "Y_t = torch.tensor(Y_np, dtype=torch.float32)\n",
        "N   = Y_t.shape[0]\n",
        "pos_counts = Y_t.sum(dim=0)\n",
        "neg_counts = N - pos_counts\n",
        "pos_weight = (neg_counts / (pos_counts + 1e-8)).to(DEVICE).float()\n",
        "\n",
        "class BertweetClassifier(nn.Module):\n",
        "    def __init__(self, model_name=\"vinai/bertweet-base\", num_labels=18,\n",
        "                 lora_r=8, lora_alpha=16, lora_dropout=0.05):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1) Load the base encoder\n",
        "        base_encoder = AutoModel.from_pretrained(model_name)  # BERTweet = RoBERTa architecture\n",
        "\n",
        "        # 2) Freeze ALL base weights\n",
        "        for p in base_encoder.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # 3) Attach LoRA adapters (these will be the ONLY trainable params inside the encoder)\n",
        "        # For RoBERTa/BERTweet, typical attention linear layers are named: query, key, value, and output.dense\n",
        "        # You can safely target: [\"query\", \"key\", \"value\", \"dense\"] (matches attention projections + output)\n",
        "        lora_cfg = LoraConfig(\n",
        "            r=lora_r,\n",
        "            lora_alpha=lora_alpha,\n",
        "            lora_dropout=lora_dropout,\n",
        "            bias=\"none\",\n",
        "            task_type=TaskType.SEQ_CLS,\n",
        "        )\n",
        "        ''''''     config = LoraConfig(\n",
        "          r=16, #attention heads\n",
        "          lora_alpha=32, #alpha scaling\n",
        "          # target_modules=[\"q_proj\", \"v_proj\"], #if you know the\n",
        "          lora_dropout=0.05,\n",
        "          bias=\"none\",\n",
        "          task_type=\"CAUSAL_LM\" # set this for CLM or Seq2Seq\n",
        "          )''''''\n",
        "        self.encoder = get_peft_model(base_encoder, lora_cfg)\n",
        "\n",
        "        # 4) Classification head (kept trainable)\n",
        "        hidden_size = self.encoder.config.hidden_size  # 768 for bertweet-base\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "        # (optional) sanity check: print trainable parameter count\n",
        "        trainable, total = 0, 0\n",
        "        for n, p in self.named_parameters():\n",
        "            total += p.numel()\n",
        "            if p.requires_grad:\n",
        "                trainable += p.numel()\n",
        "        print(f\"Trainable params: {trainable:,} / {total:,}\")\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # mean-pool over valid tokens\n",
        "        mask = attention_mask.unsqueeze(-1)\n",
        "        x = (out.last_hidden_state * mask).sum(1) / mask.sum(1).clamp(min=1e-6)\n",
        "        x = self.dropout(x)\n",
        "        return self.classifier(x)  # logits [B, num_labels]\n",
        "\n",
        "\n",
        "model = BertweetClassifier(num_labels=len(label_cols)).to(DEVICE)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "zaxKkRifUYWo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaxKkRifUYWo",
        "outputId": "487b32fc-2909-4bc7-b505-7f05ef3c36c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total params:                  134,913,810\n",
            "Trainable params:              21,277,458 (15.77%)\n",
            "  â”œâ”€ PEFT (LoRA) trainable:    0\n",
            "  â””â”€ Top-3 base trainable:     21,263,616  (layers 9â€“11, non-LoRA)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def print_trainable_breakdown(model):\n",
        "    # robust layer matcher for BERT/RoBERTa/BERTweet style names (works with PEFT wrappers too)\n",
        "    layer_rx = re.compile(\n",
        "        r\"(?:^|\\.)(?:encoder\\.layer|roberta\\.encoder\\.layer|bert\\.encoder\\.layer|model\\.encoder\\.layers)\\.(\\d+)\\.\"\n",
        "    )\n",
        "\n",
        "    total = 0\n",
        "    trainable_total = 0\n",
        "    peft_trainable = 0                  # LoRA-only (lora_A/lora_B/etc.)\n",
        "    top3_base_trainable = 0             # non-LoRA params in layers 9..11\n",
        "\n",
        "    for name, p in model.named_parameters():\n",
        "        n_params = p.numel()\n",
        "        total += n_params\n",
        "        if p.requires_grad:\n",
        "            trainable_total += n_params\n",
        "            if \"lora_\" in name:\n",
        "                peft_trainable += n_params\n",
        "            else:\n",
        "                m = layer_rx.search(name)\n",
        "                if m and int(m.group(1)) >= 9:   # last three layers\n",
        "                    top3_base_trainable += n_params\n",
        "\n",
        "    pct = 100.0 * trainable_total / total if total else 0.0\n",
        "    fmt = lambda x: f\"{x:,}\"\n",
        "\n",
        "    print(f\"Total params:                  {fmt(total)}\")\n",
        "    print(f\"Trainable params:              {fmt(trainable_total)} ({pct:.2f}%)\")\n",
        "    print(f\"  â”œâ”€ PEFT (LoRA) trainable:    {fmt(peft_trainable)}\")\n",
        "    print(f\"  â””â”€ Top-3 base trainable:     {fmt(top3_base_trainable)}  (layers 9â€“11, non-LoRA)\")\n",
        "\n",
        "# usage\n",
        "print_trainable_breakdown(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "JzCQXWhIdPpQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzCQXWhIdPpQ",
        "outputId": "cbd43f46-ae57-47ae-dbb6-9b5f0c9b171a"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "Can't pickle local object 'build_collate.<locals>.collate'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m val_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/site-packages/torch/utils/data/dataloader.py:494\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/site-packages/torch/utils/data/dataloader.py:427\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1172\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1165\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1171\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1172\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1174\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/multiprocessing/popen_spawn_posix.py:47\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     46\u001b[39m     reduction.dump(prep_data, fp)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     49\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/py312fix/lib/python3.12/multiprocessing/reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mAttributeError\u001b[39m: Can't pickle local object 'build_collate.<locals>.collate'"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "opt = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)\n",
        "scheduler = StepLR(opt, step_size=5, gamma=0.1)  # every 5 epochs, LR *= 0.1\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "best_val = float(\"inf\")   # initialize as +âˆž (so any first val_loss is smaller)\n",
        "best_state = None         # to store the best model weights\n",
        "patience = 5              # how many epochs without improvement before stopping\n",
        "bad = 0                   #\n",
        "\n",
        "epochs = 25\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        yb = batch[\"labels\"].to(DEVICE)                 # don't mutate `batch` with pop\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(DEVICE),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(DEVICE),\n",
        "        }\n",
        "        # guardrails:\n",
        "        assert \"labels\" not in inputs\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits = model(**inputs)                         # only id/mask can enter\n",
        "        loss   = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        opt.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # --- Validate (no grads) ---\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            yb = batch[\"labels\"].to(DEVICE)\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[\"input_ids\"].to(DEVICE),\n",
        "                \"attention_mask\": batch[\"attention_mask\"].to(DEVICE),\n",
        "            }\n",
        "            logits = model(**inputs)\n",
        "            val_loss += criterion(logits, yb).item()\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "\n",
        "    # Use val loss to drive LR and early stopping\n",
        "    scheduler.step(val_loss)\n",
        "    #best_val = val_loss\n",
        "    #best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "\n",
        "    if val_loss < best_val - 1e-6:\n",
        "            best_val = val_loss\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            bad = 0\n",
        "    else:\n",
        "        bad += 1\n",
        "        if bad >= patience:\n",
        "            print(\"Early stopping. Restoring best checkpoint.\")\n",
        "            model.load_state_dict(best_state)\n",
        "            break\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - train: {train_loss:.4f} - val: {val_loss:.4f} - lr: {opt.param_groups[0]['lr']:.2e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OBnHWTSfdRKZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBnHWTSfdRKZ",
        "outputId": "b451f2fe-388e-4843-892f-be53291676e0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# === Helper for prediction with probabilities ===\n",
        "def predict(texts, model, tokenizer, label_cols, max_len=128, threshold=0.5, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        enc = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            max_length=max_len,\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        logits = model(enc[\"input_ids\"], enc[\"attention_mask\"])\n",
        "        probs = torch.sigmoid(logits)  # [B, num_labels]\n",
        "        preds = (probs > threshold).int()\n",
        "\n",
        "    results = []\n",
        "    for text, row_probs, row_preds in zip(texts, probs, preds):\n",
        "        prob_dict = {label_cols[i]: float(row_probs[i]) for i in range(len(label_cols))}\n",
        "        pred_labels = [label_cols[i] for i, v in enumerate(row_preds.tolist()) if v == 1]\n",
        "        results.append({\n",
        "            \"text\": text,\n",
        "            \"labels\": pred_labels,\n",
        "            \"probabilities\": prob_dict\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "# === Example usage ===\n",
        "sample_texts = [\"he is not well\"]\n",
        "\n",
        "'''My brother has been eating more fruits and seems healthier lately.\n",
        "\n",
        "The stranger I met at the park said running helps him clear his mind.\n",
        "\n",
        "She finally took a vacation, and it did wonders for her stress levels.\n",
        "\n",
        "Our neighbor spends every evening walking his dog and looks more active now.\"]'''\n",
        "\n",
        "predictions = predict(sample_texts, model, tokenizer, label_cols, max_len=128, device=DEVICE)\n",
        "\n",
        "for pred in predictions:\n",
        "    print(f\"Text: {pred['text']}\")\n",
        "    print(f\"Predicted labels: {pred['labels']}\")\n",
        "    print(\"Probabilities:\")\n",
        "    for lbl, score in pred[\"probabilities\"].items():\n",
        "      if score>0.5:\n",
        "        print(f\"  {lbl}: {score:.3f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eNCDrctrKSp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eNCDrctrKSp",
        "outputId": "b665e4ae-7e75-4631-870f-3ff2cd794267"
      },
      "outputs": [],
      "source": [
        "import os, json, torch\n",
        "from pathlib import Path\n",
        "\n",
        "export_dir = Path(\"bertweet_multilabel_export\")\n",
        "export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) weights\n",
        "torch.save(model.state_dict(), export_dir / \"pytorch_model.bin\")\n",
        "\n",
        "# 2) tokenizer (recreate the same tokenizer object name you used)\n",
        "# If you already have `tokenizer`, just:\n",
        "tokenizer.save_pretrained(export_dir)\n",
        "\n",
        "# 3) metadata youâ€™ll need at inference time\n",
        "meta = {\n",
        "    \"model_name\": \"vinai/bertweet-base\",\n",
        "    \"num_labels\": len(label_cols),\n",
        "    \"label_cols\": list(label_cols),\n",
        "    # replace with your tuned thresholds if you have them; else 0.5 default\n",
        "    \"thresholds\": [0.5] * len(label_cols),\n",
        "    \"max_len\": 128\n",
        "}\n",
        "with open(export_dir / \"config.json\", \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "\n",
        "print(f\"Saved to: {export_dir.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r9NvjUVVUWb2",
      "metadata": {
        "id": "r9NvjUVVUWb2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py312fix",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03ff24d8b1214364851744243890cdee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "067fb3ab95b24becb73292ac7da21f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2932d165230042b7b1f7028e2f14d805",
              "IPY_MODEL_c4d57a9a2eb545bc9af5263b3453bb4f",
              "IPY_MODEL_8ce91c4875534a678c9dd2a2123e7394"
            ],
            "layout": "IPY_MODEL_3cb1702023d44dceb0a387841fc7ade3"
          }
        },
        "08a40e3ac5dd4b779d1202afe9ff3dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1905fa5bcd704293bcc05790f46e1132": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_399a396c695c4525a8bafabdc304a429",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9cfb59f0258642d38e4c51547d4e9c9b",
            "value": "â€‡1.08M/?â€‡[00:00&lt;00:00,â€‡61.6MB/s]"
          }
        },
        "2932d165230042b7b1f7028e2f14d805": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd709e77a89e455ba2d06dc19034fa4d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_79417e1e4b6643b7a50cd9b744eee536",
            "value": "config.json:â€‡100%"
          }
        },
        "2c8a5164a6cd4eed993dc0c5ea029077": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdaedc56b51e45aa853d3e2da2cf1e0c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5af646c2dee74eb083a467fd73047fb0",
            "value": 1
          }
        },
        "2dd846a313e245fab09259d31a0475b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2df930357c924f19b21bd8db99cb7e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89c55b64c2de4900b035d7bdbd57992f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e90a0e3911d3445da616f5fb96bd6cd6",
            "value": 1
          }
        },
        "2f214bac406b4af598f1040a7c177c26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3442c7e3b3fa45d58e9636e9036aee7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "399a396c695c4525a8bafabdc304a429": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b45d5d0c9564c4f86b6e980ac3e3119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3a62338819d4f8cba975375251514c6",
              "IPY_MODEL_7325666d38d146379d4861e8a4f0628f",
              "IPY_MODEL_ead5b8fbc4e348db9b06d0fd44a2005a"
            ],
            "layout": "IPY_MODEL_c569e3e9409a4ba5a2b821a2b3ec6c1a"
          }
        },
        "3cb1702023d44dceb0a387841fc7ade3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f1bb095fdd04ef3843b601b4e3e9d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40943c2d228f4b38a067cc0e16919f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4541235900854d7cad8044efb78cebbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce1105bb04304f6e956a46a15f45eae0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5ff2211a493545e19b21209c4e18f319",
            "value": "tokenizer.json:â€‡"
          }
        },
        "4566db9c918040a683d9aa8c891dba7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b8a480b521436baf978ae4a8db6d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71c498b979e64a118aeb6fee90a16ffc",
              "IPY_MODEL_ffa01401661c44b38e164b4787170663",
              "IPY_MODEL_d31c0b7e91354b22a334d8333dec2a31"
            ],
            "layout": "IPY_MODEL_2dd846a313e245fab09259d31a0475b5"
          }
        },
        "5af646c2dee74eb083a467fd73047fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ec8dfb2d1424a0f99836baa3670a112": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff2211a493545e19b21209c4e18f319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71c498b979e64a118aeb6fee90a16ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ec8dfb2d1424a0f99836baa3670a112",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3442c7e3b3fa45d58e9636e9036aee7f",
            "value": "pytorch_model.bin:â€‡100%"
          }
        },
        "7325666d38d146379d4861e8a4f0628f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f7b893532c145cdae0572bd5c494efc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d43f1725964d4d278bd6b2e3e3875dc3",
            "value": 1
          }
        },
        "7728f9c1aaba4c058df6910def8ca905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79417e1e4b6643b7a50cd9b744eee536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f7b893532c145cdae0572bd5c494efc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "851f2cb232aa43eb811beb297665d2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "878573711bd34010b2ad8c9572ab8f13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cf773da3d14953b888c69d9abde813": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8873c443c7dc47c18cb8859e64f23cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89c55b64c2de4900b035d7bdbd57992f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8ce91c4875534a678c9dd2a2123e7394": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87cf773da3d14953b888c69d9abde813",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_97852c682044491aaafcfcddc228529b",
            "value": "â€‡558/558â€‡[00:00&lt;00:00,â€‡68.3kB/s]"
          }
        },
        "944dcae8e68d43379e95445aa545e3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4541235900854d7cad8044efb78cebbe",
              "IPY_MODEL_2df930357c924f19b21bd8db99cb7e16",
              "IPY_MODEL_d96401da043a45d89c32fc4d403f895e"
            ],
            "layout": "IPY_MODEL_4566db9c918040a683d9aa8c891dba7d"
          }
        },
        "97852c682044491aaafcfcddc228529b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cfb59f0258642d38e4c51547d4e9c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d20ae96ac7e4d818cbd930ca1121dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a174a8c893f04c13af8ba0d6cb4ac51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2160e500efc4d4086b44b83de64646a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c69415d8379d4ee4af16467032c88f47",
              "IPY_MODEL_2c8a5164a6cd4eed993dc0c5ea029077",
              "IPY_MODEL_1905fa5bcd704293bcc05790f46e1132"
            ],
            "layout": "IPY_MODEL_7728f9c1aaba4c058df6910def8ca905"
          }
        },
        "c3a62338819d4f8cba975375251514c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1283937b21a418c9931ed96e02b9315",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_08a40e3ac5dd4b779d1202afe9ff3dd4",
            "value": "vocab.txt:â€‡"
          }
        },
        "c4d57a9a2eb545bc9af5263b3453bb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f760fd60a17f487291413fec137153dd",
            "max": 558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a174a8c893f04c13af8ba0d6cb4ac51b",
            "value": 558
          }
        },
        "c569e3e9409a4ba5a2b821a2b3ec6c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69415d8379d4ee4af16467032c88f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f214bac406b4af598f1040a7c177c26",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ebc7a1e12c5a4dba8af5ad9495b8296a",
            "value": "bpe.codes:â€‡"
          }
        },
        "cd709e77a89e455ba2d06dc19034fa4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdaedc56b51e45aa853d3e2da2cf1e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ce1105bb04304f6e956a46a15f45eae0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31c0b7e91354b22a334d8333dec2a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_878573711bd34010b2ad8c9572ab8f13",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_40943c2d228f4b38a067cc0e16919f3a",
            "value": "â€‡543M/543Mâ€‡[00:02&lt;00:00,â€‡290MB/s]"
          }
        },
        "d43f1725964d4d278bd6b2e3e3875dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d96401da043a45d89c32fc4d403f895e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8873c443c7dc47c18cb8859e64f23cc5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_851f2cb232aa43eb811beb297665d2c8",
            "value": "â€‡2.91M/?â€‡[00:00&lt;00:00,â€‡94.8MB/s]"
          }
        },
        "e636309ffb2643f3a940a867d87b596b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e90a0e3911d3445da616f5fb96bd6cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ead5b8fbc4e348db9b06d0fd44a2005a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d20ae96ac7e4d818cbd930ca1121dfe",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e636309ffb2643f3a940a867d87b596b",
            "value": "â€‡843k/?â€‡[00:00&lt;00:00,â€‡43.7MB/s]"
          }
        },
        "ebc7a1e12c5a4dba8af5ad9495b8296a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1283937b21a418c9931ed96e02b9315": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f760fd60a17f487291413fec137153dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa01401661c44b38e164b4787170663": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03ff24d8b1214364851744243890cdee",
            "max": 542529064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f1bb095fdd04ef3843b601b4e3e9d73",
            "value": 542529064
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
